What This Project Is

A Talent Operations chatbot backend. It turns plain questions/commands into SQL (or RPC calls) against a Supabase database, enforces role-based access, and returns clean JSON for a UI. It runs as a FastAPI service.
Key Technologies (kid-level)

FastAPI: a Python web server; it listens for HTTP requests and sends JSON back.
Uvicorn: the engine that runs FastAPI.
Supabase (with supabase-py): talks to the Postgres DB.
OpenAI client (current code uses gpt-4o-mini; can be swapped to your local Ollama).
python-dotenv: reads secrets from .env.
requests/pydantic: HTTP calls and request/response models.
Files and What They Do

.env: holds SUPABASE_URL and SUPABASE_ANON_KEY (needed to talk to Supabase).

.txt: the project brief—models, tables, required behavior, and LLM endpoint expectations.

supabase_client.py: loads .env, creates a single Supabase client (get_client() shares it).

role_engine.py: the permission map for employee, teamlead, manager, executive; helper is_allowed.

llm_service.py: calls OpenAI gpt-4o-mini to generate SQL/responses (uses OPENAI_API_KEY). If you want Ollama, this is the file to swap.

sql_agent.py: builds the big prompt with schema + rules, sends it to llm_service, returns either SQL or an action JSON (for RPCs).

main.py: FastAPI app. Routes: / (ping), /health (health), /chat (main). Flow in /chat:

Quick permission gate (infer_action + is_allowed).
Ask sql_agent to produce SQL or an action JSON.
If action JSON, call Supabase RPCs (assign_task_with_timesheet, approve_leave, upsert_timesheet, schedule_meeting_timesheet).
Else send SQL to Supabase RPC execute_sql_chatbot.
Enrich results with names from profiles_talentops.
Returns JSON (or forbidden/error).

Database Tables (from brief)

announcements_talentops, attendance_talentops, departments_talentops, expenses_talentops, leaves_talentops, notifications_talentops, payroll_talentops, payslips_talentops, performance_reviews_talentops, policies_talentops, profiles_talentops, projects_talentops, tasks_talentops, teams_talentops, timesheets_talentops.
Expected Supabase RPCs

execute_sql_chatbot(sql text) to run the generated SQL safely.
assign_task_with_timesheet, approve_leave, upsert_timesheet, schedule_meeting_timesheet (match parameter names used in main.py).

How Frontend Should Talk to /chat
Request JSON:

{
  "user_id": "<uuid>",
  "role": "employee|teamlead|manager|executive",
  "team_id": "<uuid or null>",
  "message": "natural language request"
}
Response examples:

SQL path: {"sql":"...","reply":[{"title":"Task","assigned_to_name":"Alice"}]}
Action path: {"action":"assign_task_with_timesheet","reply":{...},"message":"Assigned 'X' to bob@x.com"}
Forbidden: {"reply":"forbidden","reason":"employee cannot approve_leaves"}
Error: {"error":"details","sql":"...optional..."}
Role Guardrails (simple)

Employee: only self data; can create/edit own tasks, timesheets, leaves; view own payroll/payslip.
Teamlead: can assign/edit tasks for their team; view team leaves/timesheets; cannot approve leaves; own payroll only.
Manager/Executive: full access; can approve leaves; can view all payroll.
Run/Setup (for the next developer)

python -m pip install fastapi "uvicorn[standard]" supabase python-dotenv requests pydantic python-dateutil orjson
Set .env with SUPABASE_URL and SUPABASE_ANON_KEY; set OPENAI_API_KEY if staying on OpenAI.
Start server: uvicorn main:app --reload
Health checks: GET / and /health.
Test chat with a POST to /chat using sample payload above.
If Using Local Ollama Instead of OpenAI

Edit llm_service.py to POST http://localhost:11434/api/generate with {"model": "qwen2.5:7b", "prompt": "<text>"} and return the text body; remove OpenAI client usage. No other code changes needed.
How Pieces Connect (kid-level)

Frontend sends one JSON to /chat.
main.py checks “are you allowed?”; asks sql_agent to translate the question; llm_service talks to the LLM; Supabase runs the SQL/RPC; results come back; names are attached; JSON goes to frontend.
What to Hand Off

Repo with these files.
.env filled (not committed).
Confirm the Supabase RPCs exist and match names.
Note current LLM is OpenAI; switch llm_service.py if you want Ollama.
still more details in simple understanding language with proper connection and role everything bro


Project In Plain Words

This is a helper robot for HR/ops (Talent Ops). People type normal sentences; the robot turns them into safe database actions and answers back with tidy JSON.
FastAPI is the house where the robot lives (HTTP server). Uvicorn is the engine that runs the house.
Supabase is the database hotel. We connect with keys from .env.
An LLM (currently OpenAI in code; can swap to your local Ollama) is the translator from plain words to SQL or special actions.
Files And Roles

.env: holds SUPABASE_URL and SUPABASE_ANON_KEY (and OPENAI_API_KEY if using OpenAI). No secrets are in code.
.txt: the instruction sheet with table list, behaviors, and LLM endpoint details.
supabase_client.py: opens the door to the database once and shares that open door via get_client().
role_engine.py: the rulebook that says what each role can do. Helper is_allowed(role, action).
llm_service.py: talks to the LLM. Current code uses OpenAI gpt-4o-mini; swap to Ollama here if desired.
sql_agent.py: writes the big prompt (tables + rules + safety), sends it to the LLM, and returns either SQL or an action JSON for stored procedures.
main.py: the traffic cop. Routes:
/ and /health: quick pings.
/chat: main brain.
How /chat Works (story mode)

The frontend sends one JSON with who is speaking (user_id, role, team_id) and what they said (message).
main.py peeks at the words to guess the action (infer_action) and asks role_engine.is_allowed if that role can do it. If not, answer is {"reply": "forbidden", "reason": "..."}.
If allowed, sql_agent asks the LLM to write either:
SQL (single statement), or
An action JSON like {"action": "assign_task_with_timesheet", "params": {...}}.
If it’s an action JSON, main.py calls the matching Supabase RPC (assign_task_with_timesheet, approve_leave, upsert_timesheet, schedule_meeting_timesheet) and returns the RPC result.
If it’s SQL, main.py sends it to Supabase RPC execute_sql_chatbot and gets rows back.
If rows have user IDs, it fetches names from profiles_talentops to make replies friendly.
Sends clean JSON back to the frontend.
What The Frontend Should Send
Example POST to /chat:

{
  "user_id": "<uuid>",
  "role": "employee|teamlead|manager|executive",
  "team_id": "<uuid or null>",
  "message": "natural language question"
}
What It Sends Back

SQL path: {"sql":"...","reply":[{"title":"Task","assigned_to_name":"Alice"}]}
Action path: {"action":"assign_task_with_timesheet","reply":{...},"message":"Assigned 'X' to bob@x.com"}
Forbidden: {"reply":"forbidden","reason":"employee cannot approve_leaves"}
Error: {"error":"details","sql":"...maybe..."}
Roles In Simple Terms

Employee: sees and edits only their own stuff (tasks, timesheets, leaves). Can view their own payroll/payslip. No team-wide power.
Teamlead: can assign/edit tasks for their team, see team leaves/timesheets. Cannot approve leaves. Own payroll only.
Manager/Executive: can do everything, including approving leaves and viewing anyone’s payroll.
Tables To Know (Supabase)
announcements_talentops, attendance_talentops, departments_talentops, expenses_talentops, leaves_talentops, notifications_talentops, payroll_talentops, payslips_talentops, performance_reviews_talentops, policies_talentops, profiles_talentops, projects_talentops, tasks_talentops, teams_talentops, timesheets_talentops.

Supabase RPCs Expected

execute_sql_chatbot(sql text) to run generated SQL safely.
assign_task_with_timesheet
approve_leave
upsert_timesheet
schedule_meeting_timesheet
Names and parameter shapes must match what main.py sends.
Connections Map (kid version)

Frontend → /chat → main.py guardrail → sql_agent prompt → llm_service (LLM) → either Supabase RPC action or execute_sql_chatbot SQL → optional name lookup → JSON reply.
If Switching To Ollama

Only change llm_service.py to POST http://localhost:11434/api/generate with {"model": "qwen2.5:7b", "prompt": "<text>"} and return the text. Everything else stays.
How To Run

Install: python -m pip install fastapi "uvicorn[standard]" supabase python-dotenv requests pydantic python-dateutil orjson
.env: set SUPABASE_URL, SUPABASE_ANON_KEY, and OPENAI_API_KEY if using OpenAI.
Start server: uvicorn main:app --reload
Health check: GET /health → {"status": "ok"}.
Test chat with the sample payload above.